# -*- coding: utf-8 -*-
"""autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OSo-uUmIz2NN4D8mglwHEQRKG3enHOEV
"""

from google.colab import drive
drive.mount('/content/gdrive')

from keras.callbacks import TensorBoard
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
import cv2
import os
from PIL import Image

# Train data Loading

path1 = r"gdrive/My Drive/data compression/cleaned/Parasitized"
path2 = r"gdrive/My Drive/data compression/cleaned/Uninfected"

dir1 = os.listdir( path1 )

encoding_dim = 128

x_train = []
x_test = []
count = 0

for filename in dir1:

    try:

        #img_path = os.path.join(path1, filename)
        #img = cv2.imread(img_path, 0)
        img = Image.open(path+'/'+filename)
        img = img.resize((128,128), Image.ANTIALIAS)
        if count < 8000:
            x_train.append(np.array(img))
        elif count >= 8000 and count <8500:
            x_test.append(np.array(img))
        else:
            break
        count += 1

    except:
        continue
        
count = 0
dir2 = os.listdir( path2 )

for filename in dir2:

    try:

        #img_path = os.path.join(path2, filename)
        #img = cv2.imread(img_path, 0)
        img = Image.open(path2+'/'+filename)
        img = img.resize((128,128), Image.ANTIALIAS)
        if count < 8000:
            x_train.append(np.array(img))
        elif count >= 8000 and count < 8500:
            x_test.append(np.array(img))
        else:
            break

        count += 1

    except:
        continue

x_train = np.array(x_train)
x_test = np.array(x_test)


print(x_train.shape)
print(x_test.shape)

x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255
# 
x_train = x_train.reshape((len(x_train), 128, 128, 1))
x_test = x_test.reshape((len(x_test), 128, 128, 1))

print(x_train.shape)
print(x_test.shape)

from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras import backend as K


input_img = Input(shape=(128, 128, 1))  # adapt this if using `channels_first` image data format

x = Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
encoded = MaxPooling2D((2, 2), padding='same')(x)


# at this point the representation is (4, 4, 8) i.e. 128-dimensional

x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = UpSampling2D((2, 2))(x)
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = UpSampling2D((2, 2))(x)

decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')

autoencoder.summary()

autoencoder.fit(x_train, x_train,
                epochs=10,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test, x_test),
                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])

